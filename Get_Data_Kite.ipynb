{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "try:\n",
    "    import requests\n",
    "except ImportError:\n",
    "    os.system('python -m pip install requests')\n",
    "try:\n",
    "    import dateutil\n",
    "except ImportError:\n",
    "    os.system('python -m pip install python-dateutil')\n",
    "\n",
    "import requests\n",
    "import dateutil.parser\n",
    "\n",
    "\n",
    "def get_enctoken(userid, password, twofa):\n",
    "    session = requests.Session()\n",
    "    response = session.post('https://kite.zerodha.com/api/login', data={\n",
    "        \"user_id\": userid,\n",
    "        \"password\": password\n",
    "    })\n",
    "    response = session.post('https://kite.zerodha.com/api/twofa', data={\n",
    "        \"request_id\": response.json()['data']['request_id'],\n",
    "        \"twofa_value\": twofa,\n",
    "        \"user_id\": response.json()['data']['user_id']\n",
    "    })\n",
    "    enctoken = response.cookies.get('enctoken')\n",
    "    if enctoken:\n",
    "        return enctoken\n",
    "    else:\n",
    "        raise Exception(\"Enter valid details !!!!\")\n",
    "\n",
    "\n",
    "class KiteApp:\n",
    "    # Products\n",
    "    PRODUCT_MIS = \"MIS\"\n",
    "    PRODUCT_CNC = \"CNC\"\n",
    "    PRODUCT_NRML = \"NRML\"\n",
    "    PRODUCT_CO = \"CO\"\n",
    "\n",
    "    # Order types\n",
    "    ORDER_TYPE_MARKET = \"MARKET\"\n",
    "    ORDER_TYPE_LIMIT = \"LIMIT\"\n",
    "    ORDER_TYPE_SLM = \"SL-M\"\n",
    "    ORDER_TYPE_SL = \"SL\"\n",
    "\n",
    "    # Varities\n",
    "    VARIETY_REGULAR = \"regular\"\n",
    "    VARIETY_CO = \"co\"\n",
    "    VARIETY_AMO = \"amo\"\n",
    "\n",
    "    # Transaction type\n",
    "    TRANSACTION_TYPE_BUY = \"BUY\"\n",
    "    TRANSACTION_TYPE_SELL = \"SELL\"\n",
    "\n",
    "    # Validity\n",
    "    VALIDITY_DAY = \"DAY\"\n",
    "    VALIDITY_IOC = \"IOC\"\n",
    "\n",
    "    # Exchanges\n",
    "    EXCHANGE_NSE = \"NSE\"\n",
    "    EXCHANGE_BSE = \"BSE\"\n",
    "    EXCHANGE_NFO = \"NFO\"\n",
    "    EXCHANGE_CDS = \"CDS\"\n",
    "    EXCHANGE_BFO = \"BFO\"\n",
    "    EXCHANGE_MCX = \"MCX\"\n",
    "\n",
    "    def __init__(self, enctoken):\n",
    "        self.headers = {\"Authorization\": f\"enctoken {enctoken}\"}\n",
    "        self.session = requests.session()\n",
    "        self.root_url = \"https://api.kite.trade\"\n",
    "        # self.root_url = \"https://kite.zerodha.com/oms\"\n",
    "        self.session.get(self.root_url, headers=self.headers)\n",
    "\n",
    "    def instruments(self, exchange=None):\n",
    "        data = self.session.get(f\"{self.root_url}/instruments\",headers=self.headers).text.split(\"\\n\")\n",
    "        Exchange = []\n",
    "        for i in data[1:-1]:\n",
    "            row = i.split(\",\")\n",
    "            if exchange is None or exchange == row[11]:\n",
    "                Exchange.append({'instrument_token': int(row[0]), 'exchange_token': row[1], 'tradingsymbol': row[2],\n",
    "                                 'name': row[3][1:-1], 'last_price': float(row[4]),\n",
    "                                 'expiry': dateutil.parser.parse(row[5]).date() if row[5] != \"\" else None,\n",
    "                                 'strike': float(row[6]), 'tick_size': float(row[7]), 'lot_size': int(row[8]),\n",
    "                                 'instrument_type': row[9], 'segment': row[10],\n",
    "                                 'exchange': row[11]})\n",
    "        return Exchange\n",
    "\n",
    "    def quote(self, instruments):\n",
    "        data = self.session.get(f\"{self.root_url}/quote\", params={\"i\": instruments}, headers=self.headers).json()[\"data\"]\n",
    "        return data\n",
    "\n",
    "    def ltp(self, instruments):\n",
    "        data = self.session.get(f\"{self.root_url}/quote/ltp\", params={\"i\": instruments}, headers=self.headers).json()[\"data\"]\n",
    "        return data\n",
    "\n",
    "    def historical_data(self, instrument_token, from_date, to_date, interval, continuous=False, oi=False):\n",
    "        params = {\"from\": from_date,\n",
    "                  \"to\": to_date,\n",
    "                  \"interval\": interval,\n",
    "                  \"continuous\": 1 if continuous else 0,\n",
    "                  \"oi\": 1 if oi else 0}\n",
    "        lst = self.session.get(\n",
    "            f\"{self.root_url}/instruments/historical/{instrument_token}/{interval}\", params=params,\n",
    "            headers=self.headers).json()[\"data\"][\"candles\"]\n",
    "        records = []\n",
    "        for i in lst:\n",
    "            record = {\"date\": dateutil.parser.parse(i[0]), \"open\": i[1], \"high\": i[2], \"low\": i[3],\n",
    "                      \"close\": i[4], \"volume\": i[5],}\n",
    "            if len(i) == 7:\n",
    "                record[\"oi\"] = i[6]\n",
    "            records.append(record)\n",
    "        return records\n",
    "\n",
    "    def margins(self):\n",
    "        margins = self.session.get(f\"{self.root_url}/user/margins\", headers=self.headers).json()[\"data\"]\n",
    "        return margins\n",
    "\n",
    "    def orders(self):\n",
    "        orders = self.session.get(f\"{self.root_url}/orders\", headers=self.headers).json()[\"data\"]\n",
    "        return orders\n",
    "\n",
    "    def positions(self):\n",
    "        positions = self.session.get(f\"{self.root_url}/portfolio/positions\", headers=self.headers).json()[\"data\"]\n",
    "        return positions\n",
    "\n",
    "    def place_order(self, variety, exchange, tradingsymbol, transaction_type, quantity, product, order_type, price=None,\n",
    "                    validity=None, disclosed_quantity=None, trigger_price=None, squareoff=None, stoploss=None,\n",
    "                    trailing_stoploss=None, tag=None):\n",
    "        params = locals()\n",
    "        del params[\"self\"]\n",
    "        for k in list(params.keys()):\n",
    "            if params[k] is None:\n",
    "                del params[k]\n",
    "        order_id = self.session.post(f\"{self.root_url}/orders/{variety}\",\n",
    "                                     data=params, headers=self.headers).json()[\"data\"][\"order_id\"]\n",
    "        return order_id\n",
    "\n",
    "    def modify_order(self, variety, order_id, parent_order_id=None, quantity=None, price=None, order_type=None,\n",
    "                     trigger_price=None, validity=None, disclosed_quantity=None):\n",
    "        params = locals()\n",
    "        del params[\"self\"]\n",
    "        for k in list(params.keys()):\n",
    "            if params[k] is None:\n",
    "                del params[k]\n",
    "\n",
    "        order_id = self.session.put(f\"{self.root_url}/orders/{variety}/{order_id}\",\n",
    "                                    data=params, headers=self.headers).json()[\"data\"][\n",
    "            \"order_id\"]\n",
    "        return order_id\n",
    "\n",
    "    def cancel_order(self, variety, order_id, parent_order_id=None):\n",
    "        order_id = self.session.delete(f\"{self.root_url}/orders/{variety}/{order_id}\",\n",
    "                                       data={\"parent_order_id\": parent_order_id} if parent_order_id else {},\n",
    "                                       headers=self.headers).json()[\"data\"][\"order_id\"]\n",
    "        return order_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get enctoken from kite web \n",
    "enctoken =  \"******\"\n",
    "\n",
    "kite = KiteApp(enctoken=enctoken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kite.margins())\n",
    "print(kite.orders())\n",
    "print(kite.positions())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "instrument_token = 5633\n",
    "from_datetime = datetime.datetime.now() - datetime.timedelta(days=20)     # From last & days\n",
    "to_datetime = datetime.datetime.now()\n",
    "interval = \"minute\"\n",
    "print(kite.historical_data(instrument_token, from_datetime, to_datetime, interval, continuous=False, oi=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "# Read the stock symbols from the CSV file\n",
    "symbol_list = pd.read_csv(r\"D:\\PythonProject\\Trading\\Data\\nifty.csv\", header=0)\n",
    "\n",
    "# Set the directory path to store data and date range\n",
    "path_to_store_data = r\"D:\\PythonProject\\Trading\\Data\\Nifty_500\"\n",
    "from_date = \"2016-01-01\"\n",
    "to_date = \"2023-10-23\"\n",
    "\n",
    "# Create a directory if it doesn't exist\n",
    "if not os.path.exists(path_to_store_data + from_date + \"to\" + to_date):\n",
    "    os.makedirs(path_to_store_data + from_date + \"to\" + to_date)\n",
    "path_to_store_data = path_to_store_data + from_date + \"to\" + to_date + \"/\"\n",
    "\n",
    "# Convert string dates to datetime objects\n",
    "st = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "en = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "\n",
    "# Specify the interval for stock data\n",
    "interval = \"minute\"\n",
    "\n",
    "# Loop through the stock symbols\n",
    "for i in range(symbol_list.shape[0]):\n",
    "    # Print current index and stock ID\n",
    "    print(i)\n",
    "    ID = symbol_list.iloc[i, 1]\n",
    "    print(ID)\n",
    "    symbol_name = symbol_list.iloc[i, 0]\n",
    "    print(symbol_name)\n",
    "\n",
    "    # Initialize the start date for data retrieval\n",
    "    the_date = st\n",
    "    big_data = pd.DataFrame()\n",
    "\n",
    "    # Loop until the end date is reached\n",
    "    while the_date <= en:\n",
    "        # Define the end date for the data retrieval\n",
    "        next_date = the_date + timedelta(days=20)\n",
    "        \n",
    "        # If the next date exceeds the current date, set it to the end date\n",
    "        if next_date > datetime.now():\n",
    "            next_date = en\n",
    "\n",
    "        # Formulate the date range for data retrieval\n",
    "        dt_range = f\"{the_date}&to={next_date}\"\n",
    "        print(dt_range)\n",
    "\n",
    "        try:\n",
    "            # Retrieve historical data for the specified stock and date range\n",
    "            data = kite.historical_data(ID, the_date, next_date, interval, continuous=False, oi=False)\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            # Skip if the data length is less than 10\n",
    "            if len(df) < 10:\n",
    "                the_date += timedelta(days=50)\n",
    "                continue  # Skip the rest of the loop if the length is less than 10\n",
    "            \n",
    "            # Modify and process the retrieved data\n",
    "            df[\"SYMBOL\"] = symbol_name\n",
    "            df.columns = [\"TIME\", \"Open\", \"High\", \"Low\", \"CLOSE\", \"VOLUME\", \"SYMBOL\"]\n",
    "            df[\"TIME\"] = df[\"TIME\"].astype(str).replace(\"+0530\", \"\")\n",
    "            df[\"TIME\"] = df[\"TIME\"].astype(str).replace(\"T\", \" \")\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"TIME\"]).dt.date\n",
    "            df[\"TIME1\"] = pd.to_datetime(df[\"TIME\"]).dt.strftime(\"%H:%M:%S\")\n",
    "            big_data = pd.concat([big_data, df], ignore_index=True)\n",
    "            print(next_date)\n",
    "            \n",
    "            the_date += timedelta(days=20)\n",
    "        except Exception as e:\n",
    "            # Handle exceptions if any occur\n",
    "            print(f\"An exception occurred: {e}\")\n",
    "\n",
    "    # Define the file path to save the retrieved data as CSV\n",
    "    file_path = f\"{path_to_store_data}{symbol_name}.csv\"\n",
    "    print(file_path)\n",
    "    big_data.to_csv(file_path, index=False)\n",
    "    print(the_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use multi threading to download ans save data from zerodha web on 1 min time frame \n",
    "# time frame can be changed as per requirements \n",
    "# data availabe from 2016 only till date \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "def retrieve_data_for_symbol(ID, symbol_name, from_date, to_date, path_to_store_data, interval, kite):\n",
    "    st = datetime.strptime(from_date, \"%Y-%m-%d\")\n",
    "    en = datetime.strptime(to_date, \"%Y-%m-%d\")\n",
    "    the_date = st\n",
    "    big_data = pd.DataFrame()\n",
    "\n",
    "    while the_date <= en:\n",
    "        next_date = the_date + timedelta(days=20)\n",
    "        if next_date > datetime.now():\n",
    "            next_date = en\n",
    "\n",
    "        dt_range = f\"{the_date}&to={next_date}\"\n",
    "        \n",
    "        try:\n",
    "            data = kite.historical_data(ID, the_date, next_date, interval, continuous=False, oi=False)\n",
    "            df = pd.DataFrame(data)\n",
    "            \n",
    "            if len(df) < 10:\n",
    "                the_date += timedelta(days=50)\n",
    "                continue  # Skip the rest of the loop if the length is less than 10\n",
    "            \n",
    "            df[\"SYMBOL\"] = symbol_name\n",
    "            df.columns = [\"TIME\", \"Open\", \"High\", \"Low\", \"CLOSE\", \"VOLUME\", \"SYMBOL\"]\n",
    "            df[\"TIME\"] = df[\"TIME\"].astype(str).replace(\"+0530\", \"\")\n",
    "            df[\"TIME\"] = df[\"TIME\"].astype(str).replace(\"T\", \" \")\n",
    "            df[\"Date\"] = pd.to_datetime(df[\"TIME\"]).dt.date\n",
    "            df[\"TIME1\"] = pd.to_datetime(df[\"TIME\"]).dt.strftime(\"%H:%M:%S\")\n",
    "            big_data = pd.concat([big_data, df], ignore_index=True)\n",
    "            the_date += timedelta(days=20)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    file_path = f\"{path_to_store_data}{symbol_name}.csv\"\n",
    "    big_data.to_csv(file_path, index=False)\n",
    "\n",
    "def run_multi_threading(symbol_list, from_date, to_date, path_to_store_data, interval, num_threads, kite):\n",
    "    with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        for i in range(symbol_list.shape[0]):\n",
    "            ID = symbol_list.iloc[i, 1]\n",
    "            symbol_name = symbol_list.iloc[i, 0]\n",
    "            executor.submit(retrieve_data_for_symbol, ID, symbol_name, from_date, to_date, path_to_store_data, interval, kite)\n",
    "\n",
    "# Main execution\n",
    "symbol_list = pd.read_csv(r\"D:\\PythonProject\\Trading\\Data\\nifty.csv\", header=0)\n",
    "path_to_store_data = r\"D:\\PythonProject\\Trading\\Data\\Nifty_500\"\n",
    "from_date = \"2016-01-01\"\n",
    "to_date = \"2023-10-23\"\n",
    "interval = \"minute\"\n",
    "num_threads = 10  # You can modify the number of threads\n",
    "\n",
    "if not os.path.exists(f\"{path_to_store_data}{from_date}to{to_date}\"):\n",
    "    os.makedirs(f\"{path_to_store_data}{from_date}to{to_date}\")\n",
    "path_to_store_data = f\"{path_to_store_data}{from_date}to{to_date}/\"\n",
    "\n",
    "# Assuming you have kite initialized for fetching data\n",
    "# Replace kite with your method of fetching historical data\n",
    "\n",
    "run_multi_threading(symbol_list, from_date, to_date, path_to_store_data, interval, num_threads, kite)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(the_date)\n",
    "print(next_date)\n",
    "print(interval)\n",
    "data = kite.historical_data(4481793, the_date, next_date, interval, continuous=False, oi=False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(data)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
